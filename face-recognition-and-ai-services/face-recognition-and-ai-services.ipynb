{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition and AI Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE1: Face detect and insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The step below will import all necessary libraries throughout this lab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "!pip install tabulate\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import urllib\n",
    "import time\n",
    "import re\n",
    "import tabulate\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML, Audio\n",
    "from PIL import Image as Img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "rekognition=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's take Salah's image as an example. He is a football player, playing for Liverpool FC***    \n",
    "***Sorry if you support another team, but do not take it personally :)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source = https://www.liverpoolfc.com/news/first-team/277625-mohamed-salah-i-can-t-explain-how-it-feels-it-s-a-dream-come-true\n",
    "salah_a_url = 'https://d3j2s6hdd6a7rg.cloudfront.net/v2/uploads/media/default/0001/50/thumb_49256_default_news_size_5.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Source\" width=\"200\"/><figcaption ><center>Salah</center></figcaption></figure>'.format(salah_a_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salah_a = urllib.request.urlopen(salah_a_url)\n",
    "detect_emotion_response = rekognition.detect_faces(\n",
    "    Image={\n",
    "        'Bytes': salah_a.read()\n",
    "    },Attributes=['ALL']\n",
    ")\n",
    "print(json.dumps(detect_emotion_response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extract some interesting insight from that output***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Age Range: {}\".format(detect_emotion_response['FaceDetails'][0]['AgeRange']))\n",
    "print(\"Gender: {}\".format(detect_emotion_response['FaceDetails'][0]['Gender']))\n",
    "print(\"Smiling?: {}\".format(detect_emotion_response['FaceDetails'][0]['Smile']))\n",
    "print(\"Has beard?: {}\".format(detect_emotion_response['FaceDetails'][0]['Beard']))\n",
    "print(\"Emotions: {}\".format(json.dumps(detect_emotion_response['FaceDetails'][0]['Emotions'], indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE2: (Optional Challenge) How to be sad, angry, confused, and surprised?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now, you can try uploading your own image***    \n",
    "***The challenge is how to set our face, such that rekognition will say acknowledge that we are SAD with confidence of at least 90%***    \n",
    "***Repeat this with other emotions: confused, calm, surpirse, etc***   \n",
    "\n",
    "This is how you can upload the image. On another tab, just open the same Jupyter Notebook page. Navigate to directory machine-learning-workshop/face-recognition-and-ai-services/images, and click on the Upload button.     \n",
    "\n",
    "***Change the photo path to the path of your uploaded image.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_photo_path = 'images/yudho.jpg' # CHANGE HERE as appropriate\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Me\" width=\"200\"/><figcaption ><center>Me</center></figcaption></figure>'.format(my_photo_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_photo = open(my_photo_path, 'rb')\n",
    "detect_emotion_response = rekognition.detect_faces(\n",
    "    Image={\n",
    "        'Bytes': my_photo.read()\n",
    "    },Attributes=['ALL']\n",
    ")\n",
    "print(json.dumps(detect_emotion_response['FaceDetails'][0]['Emotions'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE3: Try face compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Define the compare_faces method first***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_faces(imageSource, imageTarget):\n",
    "\n",
    "    response=rekognition.compare_faces(SimilarityThreshold=70,\n",
    "                                  SourceImage={'Bytes': imageSource.read()},\n",
    "                                  TargetImage={'Bytes': imageTarget.read()})\n",
    "    \n",
    "    if not response['FaceMatches']:\n",
    "        print('No face match found')\n",
    "        return False\n",
    "    else:\n",
    "        for faceMatch in response['FaceMatches']:\n",
    "            position = faceMatch['Face']['BoundingBox']\n",
    "            similarity = faceMatch['Similarity']\n",
    "            print('Matched face found with ' + str(round(similarity,2)) + '% confidence\\n' +\n",
    "                  'Location in target image: {left:' +\n",
    "                   str(round(position['Left'],2)) + ',top:' +\n",
    "                   str(round(position['Top'],2)) + ',height:' +\n",
    "                   str(round(position['Height'],2)) + ',width:' +\n",
    "                   str(round(position['Width'],2)) + '}')\n",
    "            details = {\n",
    "                'confidence': similarity,\n",
    "                'left': position['Left'],\n",
    "                'top': position['Top'],\n",
    "                'height': position['Height'],\n",
    "                'width': position['Width']\n",
    "            }\n",
    "            return details\n",
    "                   \n",
    " \n",
    "    imageSource.close()\n",
    "    imageTarget.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's fetch another image of Salah for the face comparison***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source = https://www.liverpoolfc.com/news/first-team/339044-mohamed-salah-manchester-united\n",
    "salah_b_url = 'https://d3j2s6hdd6a7rg.cloudfront.net/v2/uploads/media/default/0001/82/thumb_81992_default_news_size_5.jpeg'\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Source\" width=\"300\"/><figcaption ><center>Source</center></figcaption></figure><figure style=\"float:right;\"><img src=\"{}\" alt=\"Target\" width=\"220\"/><figcaption><center>Target</center></figcaption></figure>'.format(salah_a_url, salah_b_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now let's compare the two images of Salah***    \n",
    "Notice that the target image has the face in different angle, and in different expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salah_a = urllib.request.urlopen(salah_a_url)\n",
    "salah_b = urllib.request.urlopen(salah_b_url)\n",
    "compare_1_result = compare_faces(salah_a, salah_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Salah plays with Liverpool FC. Will Rekognition be able to identify him in a picture of Liverpool players?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source = https://www.dailystar.co.uk/sport/football/631810/Liverpool-celebrate-Premier-League-Asia-Trophy-Leicester-Hong-Kong-sportgalleries\n",
    "liverpool_url = 'https://cdn.images.dailystar.co.uk/dynamic/122/photos/880000/900x738/1017880.jpg'\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Source\" width=\"300\"/><figcaption ><center>Source</center></figcaption></figure><figure style=\"float:right;\"><img src=\"{}\" alt=\"Target\" width=\"220\"/><figcaption><center>Target</center></figcaption></figure>'.format(salah_a_url, liverpool_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salah_a = urllib.request.urlopen(salah_a_url)\n",
    "liverpool = urllib.request.urlopen(liverpool_url)\n",
    "compare_2_result = compare_faces(salah_a, liverpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now, let's draw a rectangle on the matched face, based on the bounding box information returned***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image sizes\n",
    "liverpool = urllib.request.urlopen(liverpool_url)\n",
    "file = BytesIO(liverpool.read())\n",
    "width, height = Img.open(file).size\n",
    "\n",
    "# Load image to plot\n",
    "liverpool = urllib.request.urlopen(liverpool_url)\n",
    "liverpool_image = plt.imread(liverpool, format='jpg')\n",
    "\n",
    "# Get figure and axes\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(width/fig.dpi*0.8,height/fig.dpi*0.8)\n",
    "\n",
    "# Get bounding box details\n",
    "bounding_box = compare_2_result\n",
    "\n",
    "ax.imshow(liverpool_image)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "x = bounding_box['left']*width\n",
    "y = bounding_box['top']*height\n",
    "w = bounding_box['width']*width\n",
    "h = bounding_box['height']*height\n",
    "rect = patches.Rectangle((x,y),w,h,linewidth=3,edgecolor='y',facecolor='none')\n",
    "\n",
    "# Add the bounding box\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What if we present a lineup picture of Bayern Munich players? It should not find Salah in there...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source = https://fcbayern.com/en/club/honours/all-honours\n",
    "bayern_url = 'https://fcbayern.com/binaries/content/gallery/fc-bayern/homepage/club/erfolge/meisterschaft/2016_header.jpg'\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Source\" width=\"200\"/><figcaption ><center>Source</center></figcaption></figure><figure style=\"float:right;\"><img src=\"{}\" alt=\"Target\" width=\"200\"/><figcaption><center>Target</center></figcaption></figure>'.format(salah_a_url, bayern_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salah_a = urllib.request.urlopen(salah_a_url)\n",
    "bayern = urllib.request.urlopen(bayern_url)\n",
    "compare_3_result = compare_faces(salah_a, bayern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE4: Photo-ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Amazon Rekognition can recognize face in photo ID too, that could be part of real use-case feature***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_id_path = 'images/yudho-card.jpg'\n",
    "person_path = 'images/yudho.jpg'\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Source\" width=\"200\"/><figcaption ><center>Source</center></figcaption></figure><figure style=\"float:right;\"><img src=\"{}\" alt=\"Source\" width=\"120\"/><figcaption ><center>Target</center></figcaption></figure>'.format(photo_id_path, person_path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = open(person_path,'rb')\n",
    "photo_id = open(photo_id_path, 'rb')\n",
    "compare_4_result = compare_faces(person, photo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE5: Detect Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Can we extract the text in photo ID? Let's give it a try***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_id = open(photo_id_path, 'rb')\n",
    "\n",
    "def detect_text(image):\n",
    "\n",
    "    response = rekognition.detect_text(Image=\n",
    "        {'Bytes': image.read()}\n",
    "    )\n",
    "    if len(response['TextDetections']) == 0:\n",
    "        print('No Text Found')\n",
    "    else:\n",
    "        texts = []\n",
    "        for text_item in response['TextDetections']:\n",
    "            if text_item['Type'] == 'LINE':\n",
    "                texts.append(text_item['DetectedText'])\n",
    "        texts = '\\n'.join(str(x) for x in texts)\n",
    "        print(texts)\n",
    "        return(texts)\n",
    "\n",
    "# Call Amazon Rekognition detect_text API\n",
    "text_detect_result = detect_text(photo_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***You can also use Amazon Textract specific for text extraction from image.***    \n",
    "The service is currently on preview. Do sign-up to get whitelisted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE6: Discover data from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Wouldn't it be interesting to see an AI trying to understand the text and come up with meaningful information?***    \n",
    "***This AI service is called Amazon Comprehend***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "response = comprehend.detect_entities(\n",
    "    Text=text_detect_result,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "print(json.dumps(response['Entities'], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cool, but there might be only few entities found***    \n",
    "***Let's try to discover data from a more comprehensive text***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer review source = https://www.amazon.com/Mongoose-Dolomite-Mountain-26-Inch-Wheels/product-reviews/B01N2Z117A/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
    "review_file = open('texts/customer_review_example.txt','r')\n",
    "review = review_file.read()\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call comprehend detect_entities API\n",
    "response = comprehend.detect_entities(\n",
    "    Text=review,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Display in table format\n",
    "text_table = ['TEXT']\n",
    "score_table = ['CONFIDENCE SCORE']\n",
    "entity_type_table = ['ENTITY_TYPE']\n",
    "for entity in response['Entities']:\n",
    "    text_table.append(entity['Text'])\n",
    "    score_table.append(entity['Score'])\n",
    "    entity_type_table.append(entity['Type'])\n",
    "comprehend_table = [text_table, entity_type_table, score_table]\n",
    "display(HTML(tabulate.tabulate(comprehend_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We can infer the sentiment of the text too using Comprehend***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend.detect_sentiment(\n",
    "    Text=review,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note that the sentiment is overall POSITIVE, but it does have several other sentiments with low score. This is aligned with the product rating given by this customer, which is 4 out of 5***     \n",
    "\n",
    "***Try to read the review above and you may understand why the sentiment is not 100% positive***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE7: Read it out loud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's go back to the photo ID and read out the result of text detection with Amazon Polly***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polly = boto3.client('polly')\n",
    "\n",
    "def synthesize_speech(text,text_type):\n",
    "    response = polly.synthesize_speech(\n",
    "        OutputFormat='mp3',\n",
    "        SampleRate='16000',\n",
    "        Text=text,\n",
    "        TextType=text_type,\n",
    "        VoiceId='Matthew',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    return response\n",
    "    \n",
    "# Call Polly API\n",
    "voice_synthesis_result = synthesize_speech(text_detect_result,'text')\n",
    "\n",
    "# Save result to file\n",
    "file_name = 'photo_id_info.mp3'\n",
    "file = open('voices/{}'.format(file_name), 'wb')\n",
    "file.write(voice_synthesis_result['AudioStream'].read())\n",
    "file.close()\n",
    "\n",
    "\n",
    "Audio(filename='voices/{}'.format(file_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cool, but it kinda sounds weird. Let's try to improve it with SSML techniques***    \n",
    "These are techniques that we will use:    \n",
    "1. Add 1 second break after every line\n",
    "2. Add 1 second break after each word of the person's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change text format to SSML and add <break> after every line to make \n",
    "ssml_text = text_detect_result.replace('\\n','<break time=\"2s\"/>')\n",
    "ssml_text = '<speak>{}</speak>'.format(ssml_text)\n",
    "\n",
    "# Get the names and add 1s break for each word in the name\n",
    "names = text_detect_result.split('\\n')[2].split(' ')\n",
    "for name in names:\n",
    "    ssml_text = re.sub(r'(' + name + ')', r'\\1<break time=\"1s\"/>', ssml_text)\n",
    "\n",
    "print(ssml_text)\n",
    "\n",
    "# Call Polly API\n",
    "voice_synthesis_result = synthesize_speech(ssml_text,'ssml')\n",
    "\n",
    "\n",
    "# Save result to file\n",
    "file_name = 'photo_id_info.mp3'\n",
    "file = open('voices/{}'.format(file_name), 'wb')\n",
    "file.write(voice_synthesis_result['AudioStream'].read())\n",
    "file.close()\n",
    "\n",
    "\n",
    "Audio(filename='voices/{}'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE8: Transcribe it back to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This is a redundant step, I know, but the purpose is to try the transcription from voice to text using Amazon Transcribe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = boto3.client('transcribe')\n",
    "\n",
    "job_name = \"photo_id_info\"\n",
    "audio_location = 'voices/{}'.format(file_name)\n",
    "\n",
    "def start_transcription_job(job_name):\n",
    "    sts = boto3.client('sts')\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    account_id = sts.get_caller_identity().get('Account')\n",
    "    bucket_name = '{}-audio-to-transcribe'.format(account_id)\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    s3.put_object(\n",
    "        Bucket=bucket_name, \n",
    "        Key=file_name, \n",
    "        Body=open('voices/{}'.format(file_name),'rb'), \n",
    "        ACL = 'public-read'\n",
    "    )\n",
    "    job_uri = '{}/{}/{}'.format(s3.meta.endpoint_url, bucket_name, file_name)\n",
    "    \n",
    "    response = transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='mp3',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Initiate the transcription job\n",
    "start_transcription_job(job_name)\n",
    "\n",
    "# Wait until the transcription is done\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print('Completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Display the result***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URI of transcribed result\n",
    "transcribe_result_uri = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "\n",
    "# Store the result locally and open it for read\n",
    "transcribe_result_storage_path = 'texts/photo_id_info.txt'\n",
    "urllib.request.urlretrieve(transcribe_result_uri, transcribe_result_storage_path)\n",
    "file = open(transcribe_result_storage_path, 'r')\n",
    "transcript_result = file.read()\n",
    "file.close()\n",
    "\n",
    "# Display the transcription result\n",
    "transcript_result_json = json.loads(transcript_result)['results']['transcripts'][0]['transcript']\n",
    "print(transcript_result_json)\n",
    "\n",
    "# Display the transcription result with confidence details\n",
    "transcript_contents, transcript_confidence = ['WORD'], ['CONFIDENCE SCORE']\n",
    "for item in json.loads(transcript_result)['results']['items']:\n",
    "    transcript_contents.append(item['alternatives'][0]['content'])\n",
    "    transcript_confidence.append(item['alternatives'][0]['confidence'])\n",
    "transcript_table = [transcript_contents, transcript_confidence]\n",
    "display(HTML(tabulate.tabulate(transcript_table, tablefmt='html')))\n",
    "\n",
    "# Display the actual text for comparison purpose\n",
    "print(\"\\nActual:\\n\")\n",
    "print(text_detect_result.replace('\\n',' '))\n",
    "\n",
    "# Delete the transcription job\n",
    "delete_response = transcribe.delete_transcription_job(\n",
    "   TranscriptionJobName=job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note that the mis-trascribed words (if any) are mostly having low confidence score***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE9: (Optional Challenge) Improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Find a way to get 0 word mis-transcription!***\n",
    "Examples of things that we can try:    \n",
    "1. Modify the input SSML text by inserting tags, etc    \n",
    "2. Use Lexicons https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html    \n",
    "3. Increase polly syntehize transcribe rate  \n",
    "4. Change file format from mp3 to other\n",
    "5. Other creative ways....    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE10: Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now that we have the text transcribed back from audio, let's try to translate it***    \n",
    "***We pick Bahasa Indonesia as the target language for this translation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = boto3.client('translate')\n",
    "\n",
    "translate_response = translate.translate_text(\n",
    "    Text=transcript_result_json,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='id'\n",
    ")\n",
    "print(translate_response.get('TranslatedText'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE11: Confirm dominant language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***With Amazon Comprehend, we can confirm that the dominant language is indeed Bahasa Indonesia***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_dominant_language_response = comprehend.detect_dominant_language(\n",
    "    Text=translate_response.get('TranslatedText')\n",
    ")\n",
    "print(detect_dominant_language_response.get('Languages')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step RE 12: Search by face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Enough distractions. Let's go back to Amazon Rekognition for face searching***    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Define the functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "def create_collection(collectionName):\n",
    "    maxResults=1\n",
    "    collectionId=collectionName\n",
    "\n",
    "    #Create a collection\n",
    "    print('Creating collection:' + collectionId)\n",
    "    response=rekognition.create_collection(CollectionId=collectionId)\n",
    "    print('Collection ARN: ' + response['CollectionArn'])\n",
    "    print('Status code: ' + str(response['StatusCode']))\n",
    "    print('Done...')\n",
    "\n",
    "def index_face(faceName, sourceFile, collectionId):\n",
    "\n",
    "    response=rekognition.index_faces(CollectionId=collectionId,\n",
    "                                Image={'Bytes': sourceFile.read()},\n",
    "                                ExternalImageId=faceName,\n",
    "                                MaxFaces=2,\n",
    "                                QualityFilter=\"AUTO\",\n",
    "                                DetectionAttributes=['ALL'])\n",
    "\n",
    "    print ('Results for ' + faceName)\n",
    "    print('Faces indexed:')\n",
    "    for faceRecord in response['FaceRecords']:\n",
    "         print('  Face ID: ' + faceRecord['Face']['FaceId'])\n",
    "         print('  Location: {}'.format(faceRecord['Face']['BoundingBox']))\n",
    "\n",
    "    print('Faces not indexed:')\n",
    "    for unindexedFace in response['UnindexedFaces']:\n",
    "        print(' Location: {}'.format(unindexedFace['FaceDetail']['BoundingBox']))\n",
    "        print(' Reasons:')\n",
    "        for reason in unindexedFace['Reasons']:\n",
    "            print('   ' + reason)\n",
    "    return response\n",
    "\n",
    "def search_faces_by_image(sourceFile, collectionId):\n",
    "    \n",
    "    threshold = 70\n",
    "    maxFaces=1\n",
    "  \n",
    "    response=rekognition.search_faces_by_image(CollectionId=collectionId,\n",
    "                                Image={'Bytes': sourceFile.read()},\n",
    "                                FaceMatchThreshold=threshold,\n",
    "                                MaxFaces=maxFaces)\n",
    "\n",
    "                                \n",
    "    faceMatches=response['FaceMatches']\n",
    "    print ('Matching faces')\n",
    "    \n",
    "    if not faceMatches:\n",
    "        print ('No match found')\n",
    "    else:\n",
    "        for match in faceMatches:\n",
    "                print ('Match found with name ' + match['Face']['ExternalImageId'])\n",
    "                print ('Similarity: ' + \"{:.2f}\".format(match['Similarity']) + \"%\")\n",
    "                print\n",
    "    return response\n",
    "\n",
    "def delete_collection(collectionId):\n",
    "\n",
    "    print('Attempting to delete collection ' + collectionId)\n",
    "    statusCode=''\n",
    "    try:\n",
    "        response=rekognition.delete_collection(CollectionId=collectionId)\n",
    "        statusCode=response['StatusCode']\n",
    "        \n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            print ('The collection ' + collectionId + ' was not found ')\n",
    "        else:\n",
    "            print ('Error other than Not Found occurred: ' + e.response['Error']['Message'])\n",
    "        statusCode=e.response['ResponseMetadata']['HTTPStatusCode']\n",
    "    print('Operation returned Status Code: ' + str(statusCode))\n",
    "    print('Done...')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's create our first face collection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionID = 'skillful_people'\n",
    "create_collection(collectionID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***These are faces of skillful people that will be indexed***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT :** ***Upload 2 PHOTOS of your face (preferably in different emotion) to folder 'images', in jpg format***    \n",
    "How? On another tab, just open the same Jupyter Notebook page. Navigate to directory machine-learning-workshop/face-recognition-and-ai-services/images, and click on the Upload button.              \n",
    "\n",
    "We will try to test the search-by-face function, whether it will identify us correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **IMPORTANT :** ***Change the name and file name below as appropriate***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the file path to 1 of our photos uploaded to 'images' folder\n",
    "our_face_path = 'images/yudho.jpg' # CHANGE HERE as appropriate\n",
    "\n",
    "# image source = https://football-tribe.com/indonesia/2018/03/13/evan-dimas-darmono-arek-suroboyo/\n",
    "evan_dimas_url = 'https://football-tribe.com/indonesia/wp-content/uploads/sites/10/2018/03/Evan-dimas-800x449.jpg'\n",
    "\n",
    "# image source = https://www.90min.com/posts/6260670-mesut-ozil-set-to-reject-loan-move-away-from-arsenal-to-fight-for-regular-starting-spot\n",
    "mesut_ozil_url = 'https://images2.minutemediacdn.com/image/upload/c_fill,w_912,h_516,f_auto,q_auto,g_auto/shape/cover/sport/arsenal-v-qarabag-fk-uefa-europa-league-group-e-5c2b3eb8c7a324dcac000001.jpg'\n",
    "\n",
    "# image source = https://www.imdb.com/name/nm1343894/\n",
    "nicolas_anelka_url = 'https://m.media-amazon.com/images/M/MV5BNGUxMDcwOWYtNDBjMy00N2E1LWE4ZTItYmE1YmM1MDc0MWI3XkEyXkFqcGdeQXVyMjUyNDk2ODc@._V1_UX214_CR0,0,214,317_AL_.jpg'\n",
    "\n",
    "# For Salah, the urls are already saved from previous steps\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Me\" width=\"120\"/><figcaption ><center>Me</center></figcaption></figure><figure style=\"float:left;\"><img src=\"{}\" alt=\"Evan Dimas\" width=\"250\"/><figcaption><center>Evan Dimas</center></figcaption></figure><figure style=\"float:left;\"><img src=\"{}\" alt=\"Mesut Ozil\" width=\"200\"/><figcaption ><center>Mesut Ozil</center></figcaption></figure><figure style=\"float:left;\"><img src=\"{}\" alt=\"Nicolas Anelka\" width=\"120\"/><figcaption ><center>Nicolas Anelka</center></figcaption></figure><figure style=\"float:left;\"><img src=\"{}\" alt=\"Mohamed Salah\" width=\"150\"/><figcaption ><center>Mohamed Salah</center></figcaption></figure><figure style=\"float:left;\"><img src=\"{}\" alt=\"Mohamed Salah\" width=\"150\"/><figcaption ><center>Mohamed Salah</center></figcaption></figure>'.format(our_face_path, evan_dimas_url, mesut_ozil_url, nicolas_anelka_url, salah_a_url, salah_b_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Next, we need to index our face, together with other skillful people's faces to the collection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index Evan Dimas' face to our collection\n",
    "evan_dimas = urllib.request.urlopen(evan_dimas_url)\n",
    "response = index_face('evan_dimas',evan_dimas,collectionID)\n",
    "\n",
    "# Index our face to our collection\n",
    "our_face = open(our_face_path,'rb')\n",
    "response = index_face('yudho',our_face,collectionID) # Change the first argument (the index name) as appropriate\n",
    "\n",
    "# Index Mesut Ozil's face to our collection\n",
    "mesut_ozil = urllib.request.urlopen(mesut_ozil_url)\n",
    "response = index_face('mesut_ozil',mesut_ozil,collectionID)\n",
    "\n",
    "# Index Nicolas Anelka's face to our collection\n",
    "nicolas_anelka = urllib.request.urlopen(nicolas_anelka_url)\n",
    "response = index_face('nicolas_anelka',nicolas_anelka,collectionID)\n",
    "\n",
    "# Index Mohamed Salah's face to our collection\n",
    "salah_a = urllib.request.urlopen(salah_a_url)\n",
    "response = index_face('mohamed_salah',salah_a,collectionID)\n",
    "\n",
    "# Index another Mohamed Salah's face to our collection\n",
    "salah_b = urllib.request.urlopen(salah_b_url)\n",
    "response = index_face('mohamed_salah',salah_b,collectionID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** ***Change the file path below to ANOTHER photo of yours uploaded***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's do a search by image: Who is this?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the file path to ANOTHER photo of yours in 'images' folder\n",
    "sourceFile=open('images/yudho.jpg','rb') # CHANGE HERE as appropriate\n",
    "\n",
    "response = search_faces_by_image(sourceFile, collectionID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test with another person***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source = https://bola.republika.co.id/berita/sepakbola/liga-indonesia/17/11/14/ozf0ba438-jika-evan-dimas-ke-selangor-ia-akan-ikuti-jejak-4-pemain-ini\n",
    "evan_dimas_b_url = 'https://s.republika.co.id/uploads/images/inpicture_slide/evan-dimas-timnas-u19-_140206135120-764.jpg'\n",
    "\n",
    "HTML(data='<figure style=\"float:left;\"><img src=\"{}\" alt=\"Evan Dimas\" width=\"400\"/><figcaption ><center>Evan Dimas</center></figcaption></figure>'.format(evan_dimas_b_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Alright, so Rekognition, who is this person?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFile = urllib.request.urlopen(evan_dimas_b_url)\n",
    "response = search_faces_by_image(sourceFile, collectionID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Clean up time***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_collection(collectionID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
